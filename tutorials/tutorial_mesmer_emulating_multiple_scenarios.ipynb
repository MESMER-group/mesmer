{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{ prolog }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulating near surface temperature on land with MESMER\n",
    "Using calibrated parameters, we can emulate a large ensemble of realisations of near surface temperature with MESMER. To calibrate MESMER, follow the tutorials on calibrating either multiple scenarios in the Tutorial section. Here, we will emulate realisation for two scenarios predicting global mean temperature trajectories at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import filefisher\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "import mesmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load forcing data\n",
    "One can use any global mean temperature trajectory to draw gridded realisations. For this example we want to create emulations for SSP1-2.6 and SSP5-8.5 to compare the emulations to the actual ESM output. Here we concatenate historical and future simulations to create a continuous timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"IPSL-CM6A-LR\"\n",
    "scenarios = [\"ssp126\", \"ssp585\"]\n",
    "\n",
    "# some configuration parameters\n",
    "THRESHOLD_LAND = 1 / 3\n",
    "\n",
    "REFERENCE_PERIOD = slice(\"1850\", \"1900\")\n",
    "\n",
    "HIST_PERIOD = slice(\"1850\", \"2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmip_path = mesmer.example_data.cmip6_ng_path(relative=True)\n",
    "\n",
    "CMIP_FILEFINDER = filefisher.FileFinder(\n",
    "    path_pattern=cmip_path / \"{variable}/{time_res}/{resolution}\",\n",
    "    file_pattern=\"{variable}_{time_res}_{model}_{scenario}_{member}_{resolution}.nc\",\n",
    ")\n",
    "\n",
    "keys = {\"variable\": \"tas\", \"model\": model, \"resolution\": \"g025\", \"time_res\": \"ann\"}\n",
    "\n",
    "fc_scens = CMIP_FILEFINDER.find_files(keys, scenario=scenarios)\n",
    "\n",
    "members = fc_scens.df.member.unique()\n",
    "\n",
    "fc_hist = CMIP_FILEFINDER.find_files(keys, scenario=\"historical\", member=members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_hist(meta, fc_hist):\n",
    "\n",
    "    meta_hist = meta | {\"scenario\": \"historical\"}\n",
    "\n",
    "    fc = fc_hist.search(**meta_hist)\n",
    "\n",
    "    if len(fc) == 0:\n",
    "        raise FileNotFoundError(\"no hist file found\")\n",
    "    if len(fc) != 1:\n",
    "        raise ValueError(\"more than one hist file found\")\n",
    "\n",
    "    fN, meta_hist = fc[0]\n",
    "\n",
    "    return fN, meta_hist\n",
    "\n",
    "\n",
    "def load_hist(meta, fc_hist):\n",
    "    fN, __ = _get_hist(meta, fc_hist)\n",
    "\n",
    "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
    "    return xr.open_dataset(fN, decode_times=time_coder)\n",
    "\n",
    "\n",
    "def load_hist_scen_continuous(fc_hist, fc_scens):\n",
    "    dt = xr.DataTree()\n",
    "    for scen in fc_scens.df.scenario.unique():\n",
    "        files = fc_scens.search(scenario=scen)\n",
    "\n",
    "        members = []\n",
    "\n",
    "        time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
    "\n",
    "        for fN, meta in files.items():\n",
    "\n",
    "            try:\n",
    "                hist = load_hist(meta, fc_hist)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "\n",
    "            proj = xr.open_dataset(fN, decode_times=time_coder)\n",
    "\n",
    "            ds = xr.combine_by_coords(\n",
    "                [hist, proj],\n",
    "                combine_attrs=\"override\",\n",
    "                data_vars=\"minimal\",\n",
    "                compat=\"override\",\n",
    "                coords=\"minimal\",\n",
    "            )\n",
    "\n",
    "            ds = ds.drop_vars((\"height\", \"time_bnds\", \"file_qf\"), errors=\"ignore\")\n",
    "\n",
    "            # assign member-ID as coordinate\n",
    "            ds = ds.assign_coords({\"member\": meta[\"member\"]})\n",
    "\n",
    "            members.append(ds)\n",
    "\n",
    "        # create a Dataset that holds each member along the member dimension\n",
    "        scen_data = xr.concat(members, dim=\"member\")\n",
    "        # put the scenario dataset into the DataTree\n",
    "        dt[scen] = xr.DataTree(scen_data)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "tas = load_hist_scen_continuous(fc_hist, fc_scens)\n",
    "# calculate anomalies w.r.t. the reference period\n",
    "ref = tas.sel(time=REFERENCE_PERIOD).mean(\"time\")\n",
    "tas_anom = tas - ref\n",
    "# calculate global mean\n",
    "tas_globmean = mesmer.weighted.global_mean(tas_anom)\n",
    "\n",
    "# calculate smooth ensemble mean\n",
    "tas_globmean_ensmean = tas_globmean.mean(dim=\"member\")\n",
    "tas_globmean_forcing = mesmer.stats.lowess(\n",
    "    tas_globmean_ensmean,\n",
    "    dim=\"time\",\n",
    "    n_steps=30,\n",
    "    use_coords=False,\n",
    ")\n",
    "time = tas_globmean_forcing[\"ssp126\"].time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the parameters\n",
    "We load the parameters that were calibrated on historical, SSP1-2.6 and SSP5-8.5 data. But one can also use parameters that were calibrated on only one scenario. For more details on the benefits of calibrating on multiple scenarios, please refer to Beusch et al. ([2022](https://doi.org/10.5194/gmd-15-2085-2022))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the parameters - use same relative path as above\n",
    "data_path = pathlib.Path(\"./output/calibrated_parameters/\")\n",
    "\n",
    "PARAM_FILEFINDER = filefisher.FileFinder(\n",
    "    path_pattern=data_path / \"{esm}_{scen}\",\n",
    "    file_pattern=\"params_{module}_{esm}_{scen}.nc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_files = PARAM_FILEFINDER.find_files(esm=model)\n",
    "param_files.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where `scen` denotes the scenarios on which the parameters where fitted on. In this example we create emulations using the global mean temperature forcing from the same scenarios, however, this does not necessarily need to be the case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_modules = [\n",
    "    \"volcanic\",\n",
    "    \"global-variability\",\n",
    "    \"local-trends\",\n",
    "    \"local-variability\",\n",
    "    \"covariance\",\n",
    "]\n",
    "\n",
    "params = xr.DataTree()\n",
    "\n",
    "for module in all_modules:\n",
    "    params[module] = xr.DataTree(\n",
    "        xr.open_dataset(param_files.search(module=module).paths.pop()), name=module\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define seeds for global and local variability \n",
    "If we want reproducible results we need to set a seed for the random samples of global and local variability. Here, we set the seed to a chosen number, but for automated generation of seeds i.e. for several ESM we recommend using the `secrets` from the standard library. \n",
    "Then you would generate a seed using:\n",
    "\n",
    "```python\n",
    "import secrets\n",
    "\n",
    "secrets.randbits(64)\n",
    "```\n",
    "\n",
    "For reproducibility the same seeds need to be used every time, so you would copy the generated seeds to keep them unique but constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_global_variability = xr.DataTree.from_dict(\n",
    "    {\n",
    "        \"ssp126\": xr.Dataset(data_vars={\"seed\": 981}),\n",
    "        \"ssp585\": xr.Dataset(data_vars={\"seed\": 314}),\n",
    "    }\n",
    ")\n",
    "seed_local_variability = xr.DataTree.from_dict(\n",
    "    {\n",
    "        \"ssp126\": xr.Dataset(data_vars={\"seed\": 272}),\n",
    "        \"ssp585\": xr.Dataset(data_vars={\"seed\": 42}),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make emulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some settings\n",
    "n_realisations = 10\n",
    "\n",
    "buffer_global_variability = 50\n",
    "buffer_local_variability = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Adding the volcanic influence to the smooth global mean forcing\n",
    "This is optional, depending on if the used temperature forcing dataset contains a volcanic signal or not and if you want to reproduce it in the historical period. This is necessary when we want to evaluate the performance of our emulator on ESM or observation data but might not be necessary for more abstract research questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_globmean_forcing_volc = mesmer.volc.superimpose_volcanic_influence(\n",
    "    tas_globmean_forcing,\n",
    "    params[\"volcanic\"].ds,\n",
    "    hist_period=HIST_PERIOD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_globmean_forcing_volc[\"ssp126\"].to_dataset().tas.plot()\n",
    "tas_globmean_forcing_volc[\"ssp585\"].to_dataset().tas.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute global variabilty \n",
    "Draw samples from a AR process with the calibrated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_variability = mesmer.stats.draw_auto_regression_uncorrelated(\n",
    "    params[\"global-variability\"].ds,\n",
    "    realisation=n_realisations,\n",
    "    time=time,\n",
    "    seed=seed_global_variability,\n",
    "    buffer=buffer_global_variability,\n",
    ")\n",
    "global_variability = mesmer.datatree.map_over_datasets(\n",
    "    lambda ds: ds.rename({\"samples\": \"tas_resids\"}), global_variability\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compute local forced response\n",
    "Apply linear regression using the global mean forcing and the global variability as predictors. Optionally, you can also add other variables to the predictors like ocean heat content or squared global mean temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = mesmer.datatree.merge([tas_globmean_forcing_volc, global_variability])\n",
    "\n",
    "lr_params = params[\"local-trends\"].ds\n",
    "lr = mesmer.stats.LinearRegression.from_params(lr_params)\n",
    "\n",
    "# uses ``exclude`` to split the linear response\n",
    "local_forced_response = lr.predict(predictors, exclude={\"tas_resids\"})\n",
    "\n",
    "# local variability part driven by global variabilty - only from `tas_resids`\n",
    "local_variability_from_global_var = lr.predict(predictors, only={\"tas_resids\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compute local variability\n",
    "We compute the local variability by applying an AR(1) process to ensure consistency in time and adding spatially correlated innovations at each time step to get spatially coherent random samples at each gridpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_variability = mesmer.stats.draw_auto_regression_correlated(\n",
    "    params[\"local-variability\"].ds,\n",
    "    params[\"covariance\"].localized_covariance,\n",
    "    time=time,\n",
    "    realisation=n_realisations,\n",
    "    seed=seed_local_variability,\n",
    "    buffer=buffer_local_variability,\n",
    ")\n",
    "local_variability = mesmer.datatree.map_over_datasets(\n",
    "    lambda ds: ds.rename({\"samples\": \"prediction\"}), local_variability\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Add everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_variability_total = local_variability_from_global_var + local_variability\n",
    "emulations = local_forced_response + local_variability_total\n",
    "\n",
    "emulations = mesmer.datatree.map_over_datasets(\n",
    "    lambda ds: ds.rename({\"prediction\": \"tas\"}),\n",
    "    emulations,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving emulations\n",
    "We recommend saving the emulations together with the seeds used for emulating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scen in emulations:\n",
    "    local_seed = seed_local_variability[scen].seed.rename(\"seed_local_variability\")\n",
    "    global_seed = seed_global_variability[scen].seed.rename(\"seed_global_variability\")\n",
    "    emulations[scen] = xr.DataTree(\n",
    "        xr.merge([emulations[scen].ds, local_seed, global_seed])\n",
    "    )\n",
    "\n",
    "path = \"./output/emulations/\"\n",
    "# uncomment to save emulations\n",
    "# emulations.to_netcdf(path + f\"tas_emulations_{model}_ssp126-ssp585.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some example plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps of the means over all realisations for the two scenarios and their difference in 2100\n",
    "grid_orig = tas_anom[\"ssp126\"].ds[[\"lat\", \"lon\"]]\n",
    "spatial_emu_126 = mesmer.grid.unstack_lat_lon_and_align(\n",
    "    emulations[\"ssp126\"].tas, grid_orig\n",
    ")\n",
    "spatial_emu_585 = mesmer.grid.unstack_lat_lon_and_align(\n",
    "    emulations[\"ssp585\"].tas, grid_orig\n",
    ")\n",
    "\n",
    "f, axs = plt.subplots(3, 1, subplot_kw={\"projection\": ccrs.Robinson()})\n",
    "\n",
    "opt = dict(cmap=\"Reds\", transform=ccrs.PlateCarree(), vmin=0, vmax=15, extend=\"max\")\n",
    "spatial_emu_126.mean(\"realisation\").sel(time=\"2100\").plot(ax=axs[0], **opt)\n",
    "spatial_emu_585.mean(\"realisation\").sel(time=\"2100\").plot(ax=axs[1], **opt)\n",
    "\n",
    "diff = spatial_emu_585 - spatial_emu_126\n",
    "diff.mean(\"realisation\").sel(time=\"2100\").plot(\n",
    "    ax=axs[2], cmap=\"RdBu_r\", transform=ccrs.PlateCarree(), center=0\n",
    ")\n",
    "\n",
    "axs[0].set_title(\"ssp126 2100\")\n",
    "axs[1].set_title(\"ssp585 2100\")\n",
    "axs[2].set_title(\"Difference\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.coastlines()\n",
    "    ax.set_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot global land means\n",
    "globmean_126 = mesmer.weighted.global_mean(spatial_emu_126)\n",
    "globmean_585 = mesmer.weighted.global_mean(spatial_emu_585)\n",
    "\n",
    "globmean_126_smoothed = mesmer.stats.lowess(\n",
    "    globmean_126.mean(\"realisation\"), dim=\"time\", n_steps=50, use_coords=False\n",
    ")\n",
    "globmean_585_smoothed = mesmer.stats.lowess(\n",
    "    globmean_585.mean(\"realisation\"), dim=\"time\", n_steps=50, use_coords=False\n",
    ")\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "globmean_585.plot.line(x=\"time\", ax=ax, add_legend=False, color=\"lightblue\")\n",
    "globmean_126.plot.line(x=\"time\", ax=ax, add_legend=False, color=\"pink\")\n",
    "\n",
    "globmean_585_smoothed.plot.line(x=\"time\", ax=ax, color=\"blue\", label=\"ssp585\")\n",
    "globmean_126_smoothed.plot.line(x=\"time\", ax=ax, color=\"red\", label=\"ssp126\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qq plot between ESM and emulation\n",
    "esm_ssp585 = tas_anom[\"ssp585\"].ds\n",
    "\n",
    "\n",
    "def mask(ds, threshold_land):\n",
    "    ds = mesmer.mask.mask_ocean_fraction(ds, threshold_land)\n",
    "    ds = mesmer.mask.mask_antarctica(ds)\n",
    "    return ds\n",
    "\n",
    "\n",
    "esm_ssp585 = mask(esm_ssp585, THRESHOLD_LAND)\n",
    "\n",
    "esm_ssp585 = esm_ssp585.tas.stack(sample=(\"time\", \"lat\", \"lon\", \"member\"))\n",
    "emu_ssp585 = spatial_emu_585.stack(sample=(\"time\", \"lat\", \"lon\", \"realisation\"))\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sm.qqplot_2samples(esm_ssp585, emu_ssp585, line=\"45\")\n",
    "plt.xlabel(\"ESM\")\n",
    "plt.ylabel(\"Emulation\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesmer_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

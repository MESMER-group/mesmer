{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{ prolog }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MESMER-M workflow for multiple scenarios\n",
    "\n",
    "Training and emulation of monthly local temperature from yearly local temperature for multiple scenarios and ensemble members. We use an example data set on a coarse grid. This roughly follows the approach outlined in Nath et al. ([2022](https://esd.copernicus.org/articles/13/851/2022/)).\n",
    "\n",
    "\n",
    "MESMER-M trains the local monthly temperature using the local annual temperature (i.e. the temperature from the same grid point) as forcing. This is different from MESMER which uses global mean values as predictors for where local annual mean temperatures. Training MESMER-M consists of 4 steps:\n",
    "\n",
    "* **harmonic model**: fit the seasonal cycle with a harmonic model\n",
    "* **power transformer**: make the resulting residuals more normal by using a Yeo-Johnson transformation\n",
    "* **cyclo-stationary AR(1) process**: the monthly residuals are assumed to follow a cyclo-stationary AR(1) process, where one months value depends on the previous one\n",
    "* **local variability**: estimate parameters needed to generate local variability\n",
    "\n",
    "This example can be extended to more scenarios, ensemble members and higher resolution data. See also the MESMER-M calibration and emulation tests in *tests/integration/*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filefisher\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import xarray as xr\n",
    "\n",
    "import mesmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCALISATION_RADII = list(range(7_500, 12_501, 500))\n",
    "THRESHOLD_LAND = 1 / 3\n",
    "REFERENCE_PERIOD = slice(\"1850\", \"1900\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model and scenarios\n",
    "model = \"IPSL-CM6A-LR\"\n",
    "scenarios = [\"ssp126\", \"ssp585\"]\n",
    "\n",
    "# path of the example data\n",
    "cmip6_data_path = mesmer.example_data.cmip6_ng_path(relative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data for training the emulator\n",
    "\n",
    "We load monthly and annual mean temperatures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_FILEFINDER = filefisher.FileFinder(\n",
    "    path_pattern=cmip6_data_path / \"{variable}/{time_res}/{resolution}\",\n",
    "    file_pattern=\"{variable}_{time_res}_{model}_{scenario}_{member}_{resolution}.nc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find annual data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_scens_y = CMIP_FILEFINDER.find_files(\n",
    "    variable=\"tas\", scenario=scenarios, model=model, resolution=\"g025\", time_res=\"ann\"\n",
    ")\n",
    "\n",
    "# get the historical members that are also in the future scenarios, but only once\n",
    "unique_scen_members_y = fc_scens_y.df.member.unique()\n",
    "\n",
    "fc_hist_y = CMIP_FILEFINDER.find_files(\n",
    "    variable=\"tas\",\n",
    "    scenario=\"historical\",\n",
    "    model=model,\n",
    "    resolution=\"g025\",\n",
    "    time_res=\"ann\",\n",
    "    member=unique_scen_members_y,\n",
    ")\n",
    "\n",
    "fc_all_y = fc_hist_y.concat(fc_scens_y)\n",
    "fc_all_y.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find monthly data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_scens_m = CMIP_FILEFINDER.find_files(\n",
    "    variable=\"tas\", scenario=scenarios, model=model, resolution=\"g025\", time_res=\"mon\"\n",
    ")\n",
    "\n",
    "# get the historical members that are also in the future scenarios, but only once\n",
    "unique_scen_members_m = fc_scens_y.df.member.unique()\n",
    "\n",
    "fc_hist_m = CMIP_FILEFINDER.find_files(\n",
    "    variable=\"tas\",\n",
    "    scenario=\"historical\",\n",
    "    model=model,\n",
    "    resolution=\"g025\",\n",
    "    time_res=\"mon\",\n",
    "    member=unique_scen_members_m,\n",
    ")\n",
    "\n",
    "fc_all_m = fc_hist_m.concat(fc_scens_m)\n",
    "fc_all_m.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This found 1 ensemble member for SSP1-2.6 and two for SSP5-8.5 and the corresponding ones in the historical scenario.\n",
    "\n",
    "To load the data we write a small helper function that loads the data into a `DataTree` (where each node is a scenario):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filecontainer):\n",
    "\n",
    "    out = xr.DataTree()\n",
    "\n",
    "    scenarios = filecontainer.df.scenario.unique().tolist()\n",
    "\n",
    "    # load data for each scenario\n",
    "    for scen in scenarios:\n",
    "        files = filecontainer.search(scenario=scen)\n",
    "\n",
    "        # load all members for a scenario\n",
    "        members = []\n",
    "        for fN, meta in files.items():\n",
    "            time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
    "            ds = xr.open_dataset(fN, decode_times=time_coder)\n",
    "            # drop unnecessary variables\n",
    "            ds = ds.drop_vars([\"height\", \"time_bnds\", \"file_qf\"], errors=\"ignore\")\n",
    "            # assign member-ID as coordinate\n",
    "            ds = ds.assign_coords({\"member\": meta[\"member\"]})\n",
    "            members.append(ds)\n",
    "\n",
    "        # create a Dataset that holds each member along the member dimension\n",
    "        scen_data = xr.concat(members, dim=\"member\")\n",
    "        # put the scenario dataset into the DataTree\n",
    "        out[scen] = xr.DataTree(scen_data)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load annual and monthly data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_y_orig = load_data(fc_all_y)\n",
    "tas_m_orig = load_data(fc_all_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in two `DataTree` objects, with 3 nodes, one for each scenario (click on `Groups` to see the individual `Datasets` for the three scenarios):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_y_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Calculate anomalies w.r.t the reference period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_anoms_y = mesmer.anomaly.calc_anomaly(tas_y_orig, reference_period=REFERENCE_PERIOD)\n",
    "tas_anoms_m = mesmer.anomaly.calc_anomaly(tas_m_orig, reference_period=REFERENCE_PERIOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use land grid points and exclude Antarctica. The 3D data with dimensions `('time', 'lat', 'lon')` is stacked to 2D data with dimensions `('time', 'gridcell')`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_and_stack(ds, threshold_land):\n",
    "    ds = mesmer.mask.mask_ocean_fraction(ds, threshold_land)\n",
    "    ds = mesmer.mask.mask_antarctica(ds)\n",
    "    ds = mesmer.grid.stack_lat_lon(ds)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_y = mask_and_stack(tas_anoms_y, threshold_land=THRESHOLD_LAND)\n",
    "tas_m = mask_and_stack(tas_anoms_m, threshold_land=THRESHOLD_LAND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we pool all scenarios, and ensemble members into one dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_pooled_y = mesmer.datatree.pool_scen_ens(tas_y)\n",
    "tas_pooled_m = mesmer.datatree.pool_scen_ens(tas_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get a `Dataset` where `scenario`, `member`, and `time` is pooled along a `sample` dimension. `scenario`, `member`, and `time` are kept as non-dimension coordinates, so we still know where each point comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_pooled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pooling(data):\n",
    "\n",
    "    mi = pd.MultiIndex.from_arrays([data[\"scenario\"].values, data[\"member\"].values])\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "\n",
    "    data.plot()\n",
    "\n",
    "    xticks, xticklabels = [], []\n",
    "    for i in mi.unique():\n",
    "\n",
    "        loc = mi.get_loc(i)\n",
    "        center = loc.start + (loc.stop - loc.start) / 2\n",
    "\n",
    "        plt.axvline(loc.stop, color=\"0.1\", lw=0.5)\n",
    "        xticklabels.append(\"\\n\".join(i))\n",
    "        xticks.append(center)\n",
    "\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "    ax.xaxis.set_tick_params(length=0)\n",
    "    ax.set_title(\"visualize pooling scenarios and ensemble members\")\n",
    "    ax.set_xlim(0, data.sample.size)\n",
    "\n",
    "\n",
    "visualize_pooling(tas_pooled_y.tas.isel(gridcell=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the harmonic model\n",
    "\n",
    "With all the data preparation done we can now calibrate the different steps of MESMER-M. First we fit the seasonal cycle with a harmonic model which can vary with local annual mean temperature (fourier regression). This step removes the annual mean and determines the optimal order and the coefficients of the harmonic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_model_fit = mesmer.stats.fit_harmonic_model(tas_pooled_y.tas, tas_pooled_m.tas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_model_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the power transformer\n",
    "\n",
    "The residuals are not necessarily symmetric - make them more normal using a Yeo-Johnson transformation. For performance reasons we use a constant $\\lambda$ here. Originally, the parameter $\\lambda$ is modelled with a logistic regression using local annual mean temperature as covariate (Nath et al., [2022](https://esd.copernicus.org/articles/13/851/2022/)). Currently `\"constant\"` and `\"logistic\"` covariance structures are implemented - further options could be implemented and tested.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yj_transformer = mesmer.stats.YeoJohnsonTransformer(\"logistic\")\n",
    "\n",
    "yj_transformer = mesmer.stats.YeoJohnsonTransformer(\"constant\")\n",
    "\n",
    "pt_coefficients = yj_transformer.fit(tas_pooled_y.tas, harmonic_model_fit.residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_resids = yj_transformer.transform(\n",
    "    tas_pooled_y.tas,\n",
    "    harmonic_model_fit.residuals,\n",
    "    pt_coefficients,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate this we plot the skewness of the original and the transformed residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "\n",
    "ax.plot(\n",
    "    sp.stats.skew(harmonic_model_fit.residuals, axis=0),\n",
    "    label=\"original residuals\",\n",
    ")\n",
    "ax.plot(\n",
    "    sp.stats.skew(transformed_resids.transformed.T, axis=0),\n",
    "    label=\"transformed residuals\",\n",
    ")\n",
    "\n",
    "ax.axhline(0, lw=0.5, color=\"0.1\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Skewness of residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit cyclo-stationary AR(1) process\n",
    "\n",
    "The monthly residuals are now assumed to follow a cyclo-stationary AR(1) process, where e.g. the July residuals depend on the ones from June and the ones of June on May's with distinct parameters. Because the first timestep has no previous one, we loose one time step of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1_fit = mesmer.stats.fit_auto_regression_monthly(transformed_resids.transformed)\n",
    "ar1_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find localized empirical covariance\n",
    "\n",
    "Finally, we determine the localized empirical spatial covariance for each month separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodist = mesmer.geospatial.geodist_exact(tas_y.historical.lon, tas_y.historical.lat)\n",
    "\n",
    "phi_gc_localizer = mesmer.stats.gaspari_cohn_correlation_matrices(\n",
    "    geodist, localisation_radii=LOCALISATION_RADII\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = mesmer.weighted.equal_scenario_weights_from_datatree(tas_anoms_m)\n",
    "weights = mesmer.datatree.pool_scen_ens(weights)\n",
    "\n",
    "# because ar1_fit.residuals lost the first ts, we have to remove it here as well\n",
    "weights = weights.isel(sample=slice(1, None))\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more samples we pass to `find_localized_empirical_covariance_monthly`, the estimated localisation radius becomes larger. You may want to pass more `LOCALISATION_RADII` than we do here (however, the function warns if either the smallest or largest localisation radius is chosen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localized_ecov = mesmer.stats.find_localized_empirical_covariance_monthly(\n",
    "    ar1_fit.residuals,\n",
    "    weights.weights,\n",
    "    phi_gc_localizer,\n",
    "    dim=\"time\",\n",
    "    k_folds=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localized_ecov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time coordinate\n",
    "We need to get the original time coordinate to be able to validate our results later on. If it is not needed to align the final emulations with the original data, this can be omitted, the time coordinates can later be generated for example with \n",
    "\n",
    "\n",
    "```python\n",
    "monthly_time = xr.cftime_range(\"1850-01-01\", \"2100-12-31\", freq=\"MS\", calendar=\"gregorian\")\n",
    "monthly_time = xr.DataArray(monthly_time, dims=\"time\", coords={\"time\": monthly_time})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and save time coordinate\n",
    "hist_time = tas_m.historical.time\n",
    "scen_time = tas_m.ssp585.time\n",
    "m_time = xr.concat([hist_time, scen_time], dim=\"time\")\n",
    "\n",
    "# TODO\n",
    "# save the parameters to a file\n",
    "# harmonic_model_fit\n",
    "# pt_coefficients\n",
    "# ar1_fit\n",
    "# localized_ecov\n",
    "# m_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make emulations\n",
    "\n",
    "To generate emulations the workflow of the calibration is reversed, using the estimated parameters from above. Here, we use the same local annual mean temperatures to force the emulations, but temperatures from other models, scenarios, ensemble members or emulated annual local temperatures can be used as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Re-import necessary libraries\n",
    "# import matplotlib.pyplot as plt\n",
    "# import xarray as xr\n",
    "\n",
    "# import mesmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "NR_EMUS = 10\n",
    "BUFFER = 20\n",
    "# REF_PERIOD = slice(\"1850\", \"1900\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random number seed\n",
    "\n",
    "The `seed` determines the initial state for the random number generator. To avoid generating the same noise for different models and scenarios different seeds are required for each individual paring. For reproducibility the seed needs to be the same for any subsequent draw of the same emulator. To avoid human chosen standard seeds (e.g. `0`, `1234`) its recommended to also randomly generate the seeds and save them for later, using\n",
    "\n",
    "```python\n",
    "import secrets\n",
    "secrets.randbits(128)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random but constant\n",
    "SEED = 172968389139962348981869773740375508145"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data needed for emulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load the parameters from a file\n",
    "# in this example notebook we directly use the calibration from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load yearly temperature\n",
    "# in this example we are using the original yearly temperature for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess tas\n",
    "# ref = tas_y.sel(time=REF_PERIOD).mean(\"time\", keep_attrs=True)\n",
    "# tas_y = tas_y - ref\n",
    "# tas_stacked_y = mask_and_stack(tas_y, threshold_land=THRESHOLD_LAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the original grid for transforming back later\n",
    "grid_orig = tas_anoms_y[\"historical\"].to_dataset()[[\"lat\", \"lon\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate historical and scenario annual mean temperature timeseries. We use this as predictor for our emulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_predictor = xr.concat(\n",
    "    [\n",
    "        tas_y.historical.tas.sel(member=\"r1i1p1f1\"),\n",
    "        tas_y.ssp585.tas.sel(member=\"r1i1p1f1\"),\n",
    "    ],\n",
    "    dim=\"time\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate emulations\n",
    "\n",
    "To generate emulations we have to invert the steps done in the calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate monthly data with harmonic model\n",
    "monthly_harmonic_emu = mesmer.stats.predict_harmonic_model(\n",
    "    yearly_predictor, harmonic_model_fit.coeffs, m_time\n",
    ")\n",
    "\n",
    "# generate variability around 0 with AR(1) model\n",
    "local_variability_transformed = mesmer.stats.draw_auto_regression_monthly(\n",
    "    ar1_fit,\n",
    "    localized_ecov.localized_covariance,\n",
    "    time=m_time,\n",
    "    n_realisations=NR_EMUS,\n",
    "    seed=SEED,\n",
    "    buffer=BUFFER,\n",
    ")\n",
    "\n",
    "# invert the power transformation\n",
    "yj_transformer = mesmer.stats.YeoJohnsonTransformer(\"constant\")\n",
    "local_variability_inverted = yj_transformer.inverse_transform(\n",
    "    yearly_predictor,\n",
    "    local_variability_transformed.samples,\n",
    "    pt_coefficients,\n",
    ")\n",
    "\n",
    "# add the local variability to the monthly harmonic\n",
    "emulations = monthly_harmonic_emu + local_variability_inverted.inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and/or Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The emulations are still stacked - to get back to the lat/ lon grid we have to unstack them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstack to original grid\n",
    "emulations_unstacked = mesmer.grid.unstack_lat_lon_and_align(emulations, grid_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then visualize a random month of the emulated temperature fields - e.g. May 2000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulations_unstacked.isel(realisation=0).sel(time=\"2000-05\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or compare the original monthly time series to our emulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcell = 0\n",
    "time_period = slice(None, 60)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "# loop realisations\n",
    "for i in range(10):\n",
    "    d = emulations.isel(gridcell=gridcell, realisation=i, time=time_period)\n",
    "    d.plot(ax=ax, color=\"0.5\")\n",
    "\n",
    "\n",
    "# show original time series\n",
    "d = tas_m[\"historical\"].sel(member=\"r1i1p1f1\")\n",
    "d = d.isel(gridcell=gridcell, time=time_period)\n",
    "d.tas.plot(color=\"#1f78b4\", label=\"Original time series\")\n",
    "\n",
    "# legend entry\n",
    "ax.plot([], [], color=\"0.5\", label=\"Emulated ensemble member\")\n",
    "\n",
    "ax.set_title(\"Original vs. emulated time series\")\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mesmer_dev]",
   "language": "python",
   "name": "conda-env-.conda-mesmer_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

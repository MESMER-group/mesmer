{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example execution of MESMER-M workflow for multiple scenarios and ensemble members\n",
    "Training and emulation of monthly local temperature from yearly local temperature. We use an example data set on a coarse (20° x 20°) grid.\n",
    "\n",
    "Import libraries and check MESMER version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import filefisher\n",
    "import pandas\n",
    "import xarray as xr\n",
    "from filefinder import FileContainer\n",
    "\n",
    "import mesmer\n",
    "from mesmer.core._datatreecompat import map_over_datasets\n",
    "\n",
    "mesmer.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate emulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCALISATION_RADII = list(range(1250, 6251, 250)) + list(range(6500, 8501, 500))\n",
    "THRESHOLD_LAND = 1 / 3\n",
    "REF_PERIOD = slice(\"1850\", \"1900\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths of the example data\n",
    "\n",
    "model = \"IPSL-CM6A-LR\"\n",
    "scenarios = [\"ssp585\", \"ssp126\"]\n",
    "\n",
    "TEST_DATA_PATH = importlib.resources.files(\"mesmer\").parent / \"tests\" / \"test-data\"\n",
    "cmip6_data_path = TEST_DATA_PATH / \"calibrate-coarse-grid\" / \"cmip6-ng\"\n",
    "\n",
    "path_tas_mon = cmip6_data_path / \"tas\" / \"mon\" / \"g025\"\n",
    "fN_hist_mon = path_tas_mon / f\"tas_mon_{model}_historical_r1i1p1f1_g025.nc\"\n",
    "fN_proj_mon = path_tas_mon / f\"tas_mon_{model}_ssp585_r1i1p1f1_g025.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data for training the emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_FILEFINDER = filefisher.FileFinder(\n",
    "    path_pattern=cmip6_data_path / \"{variable}/{time_res}/{resolution}\",\n",
    "    file_pattern=\"{variable}_{time_res}_{model}_{scenario}_{member}_{resolution}.nc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_scens_y = CMIP_FILEFINDER.find_files(\n",
    "    variable=\"tas\", scenario=scenarios, model=model, resolution=\"g025\", time_res=\"ann\"\n",
    ")\n",
    "\n",
    "# only get the historical members that are also in the future scenarios, but only once\n",
    "unique_scen_members_y = fc_scens_y.df.member.unique()\n",
    "\n",
    "fc_hist_y = CMIP_FILEFINDER.find_files(\n",
    "    variable=\"tas\",\n",
    "    scenario=\"historical\",\n",
    "    model=model,\n",
    "    resolution=\"g025\",\n",
    "    time_res=\"ann\",\n",
    "    member=unique_scen_members_y,\n",
    ")\n",
    "\n",
    "fc_all_y = FileContainer(pandas.concat([fc_hist_y.df, fc_scens_y.df]))\n",
    "fc_all_y.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_scens_m = CMIP_FILEFINDER.find_files(\n",
    "    variable=\"tas\", scenario=scenarios, model=model, resolution=\"g025\", time_res=\"mon\"\n",
    ")\n",
    "\n",
    "# only get the historical members that are also in the future scenarios, but only once\n",
    "unique_scen_members_m = fc_scens_y.df.member.unique()\n",
    "\n",
    "fc_hist_m = CMIP_FILEFINDER.find_files(\n",
    "    variable=\"tas\",\n",
    "    scenario=\"historical\",\n",
    "    model=model,\n",
    "    resolution=\"g025\",\n",
    "    time_res=\"mon\",\n",
    "    member=unique_scen_members_m,\n",
    ")\n",
    "\n",
    "fc_all_m = FileContainer(pandas.concat([fc_hist_m.df, fc_scens_m.df]))\n",
    "fc_all_m.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_y = xr.DataTree()\n",
    "\n",
    "scenarios_whist = scenarios.copy()\n",
    "scenarios_whist.append(\"historical\")\n",
    "\n",
    "# load data for each scenario\n",
    "for scen in scenarios_whist:\n",
    "    files = fc_all_y.search(scenario=scen)\n",
    "\n",
    "    # load all members for a scenario\n",
    "    members = []\n",
    "    for fN, meta in files:\n",
    "        ds = xr.open_dataset(fN, use_cftime=True)\n",
    "        # drop unnecessary variables\n",
    "        ds = ds.drop_vars([\"height\", \"time_bnds\", \"file_qf\"], errors=\"ignore\")\n",
    "        # assign member-ID as coordinate\n",
    "        ds = ds.assign_coords({\"member\": meta[\"member\"]})\n",
    "        members.append(ds)\n",
    "\n",
    "    # create a Dataset that holds each member along the member dimension\n",
    "    scen_data = xr.concat(members, dim=\"member\")\n",
    "    # put the scenario dataset into the DataTree\n",
    "    tas_y[f\"{scen}\"] = xr.DataTree(scen_data)\n",
    "\n",
    "tas_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_m = xr.DataTree()\n",
    "\n",
    "scenarios_whist = scenarios.copy()\n",
    "scenarios_whist.append(\"historical\")\n",
    "\n",
    "# load data for each scenario\n",
    "for scen in scenarios_whist:\n",
    "    files = fc_all_m.search(scenario=scen)\n",
    "\n",
    "    # load all members for a scenario\n",
    "    members = []\n",
    "    for fN, meta in files:\n",
    "        ds = xr.open_dataset(fN, use_cftime=True)\n",
    "        # drop unnecessary variables\n",
    "        ds = ds.drop_vars([\"height\", \"time_bnds\", \"file_qf\"], errors=\"ignore\")\n",
    "        # assign member-ID as coordinate\n",
    "        ds = ds.assign_coords({\"member\": meta[\"member\"]})\n",
    "        members.append(ds)\n",
    "\n",
    "    # create a Dataset that holds each member along the member dimension\n",
    "    scen_data = xr.concat(members, dim=\"member\")\n",
    "    # put the scenario dataset into the DataTree\n",
    "    tas_m[f\"{scen}\"] = xr.DataTree(scen_data)\n",
    "\n",
    "tas_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Calculate anomalies w.r.t the reference period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_y = mesmer.anomaly.calc_anomaly(tas_y, reference_period=REF_PERIOD)\n",
    "ref_m = mesmer.anomaly.calc_anomaly(tas_m, reference_period=REF_PERIOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use land grid points and exclude Antarctica. The 3D data with dimensions `('time', 'lat', 'lon')` is stacked to 2D data with dimensions `('time', 'gridcell')`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_and_stack(ds, threshold_land):\n",
    "    ds = mesmer.mask.mask_ocean_fraction(ds, threshold_land)\n",
    "    ds = mesmer.mask.mask_antarctica(ds)\n",
    "    ds = mesmer.grid.stack_lat_lon(ds)\n",
    "    # ds = ds.stack(sample = (\"member\", \"time\"))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_stacked_y = map_over_datasets(mask_and_stack, tas_y, kwargs={\"threshold_land\": THRESHOLD_LAND})\n",
    "tas_stacked_m = map_over_datasets(mask_and_stack, tas_m, kwargs={\"threshold_land\": THRESHOLD_LAND})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_stacked_y[\"ssp585\"].tas.isel(gridcell=0).plot(x=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the harmonic model\n",
    "\n",
    "Fit the seasonal cycle with a harmonic model which can vary with local annual mean temperature\n",
    "(fourier regression). Removes annual mean and, determines the optimal order and the coefficients\n",
    "of the harmonic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_da_and_call_func(func, *names):\n",
    "    # TODO: find a better solution for this\n",
    "\n",
    "    def inner(*args, **kwargs):\n",
    "\n",
    "        assert len(names) == len(args)\n",
    "\n",
    "        args = (arg[name] if name is not None else arg for name, arg in zip(names, args))\n",
    "\n",
    "        out = func(*args, **kwargs)\n",
    "        return out\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_model_fit = map_over_datasets(\n",
    "    extract_da_and_call_func(mesmer.stats.fit_harmonic_model, \"tas\", \"tas\"),\n",
    "    tas_stacked_y,\n",
    "    tas_stacked_m\n",
    ")\n",
    "harmonic_model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _avg_for_dtype(ds, dim):\n",
    "    def avg_da(da, dim):\n",
    "        if da.dtype == int:\n",
    "            return da.quantile(q=0.5, dim=dim, method=\"nearest\", skipna=True)\n",
    "        else:\n",
    "            return da.mean(dim=dim, skipna=True)\n",
    "\n",
    "    return ds.map(avg_da, dim=dim)\n",
    "\n",
    "\n",
    "def _avg_ens_then_scen(dt, ens_dim=\"member\"):\n",
    "    ens_mean = map_over_datasets(_avg_for_dtype, dt, kwargs={\"dim\": ens_dim})\n",
    "    ds_ens_mean = mesmer.datatree.collapse_datatree_into_dataset(\n",
    "        ens_mean, dim=\"scenario\"\n",
    "    )\n",
    "    scen_mean = _avg_for_dtype(ds_ens_mean, dim=\"scenario\")\n",
    "    return scen_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over ensemble members and scenarios\n",
    "# do not average predictions, drop time dim (is only present on predicitions) to avoid nans\n",
    "harmonic_model_fit_wo_preds = harmonic_model_fit\n",
    "#.drop_vars((\"predictions\", \"time\"))\n",
    "harmonic_model_fit_scen_mean = _avg_ens_then_scen(\n",
    "    harmonic_model_fit_wo_preds\n",
    ")\n",
    "#.drop_vars(\"quantile\")\n",
    "harmonic_model_fit_scen_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the power transformer\n",
    "\n",
    "The residuals are not necessarily symmetric - make them more normal using a Yeo-Johnson\n",
    "transformation. The parameter $\\lambda$ is modelled with a logistic regression using\n",
    "local annual mean temperature as covariate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# harmonic_model_predictions = harmonic_model\n",
    "resids_after_hm = map_over_datasets(lambda m_dat, hm_dat: m_dat - hm_dat.predictions,\n",
    "    tas_stacked_m, harmonic_model_fit\n",
    ")\n",
    "resids_after_hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_coefficients = map_over_datasets(extract_da_and_call_func,\n",
    "    mesmer.stats.fit_yeo_johnson_transform, tas_stacked_y, resids_after_hm\n",
    ")\n",
    "pt_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_coefficients_scen_mean = _avg_ens_then_scen(pt_coefficients)\n",
    "pt_coefficients_scen_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_das_and_call_yeo_johnson_transform(ds_y, ds_m, lambda_coeffs_ds):\n",
    "    yearly_dat = ds_y.tas\n",
    "    monthly_dat = ds_m.tas\n",
    "    lambda_coeffs = lambda_coeffs_ds.lambda_coeffs\n",
    "    return mesmer.stats.yeo_johnson_transform(yearly_dat, monthly_dat, lambda_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_hm_resids = map_over_datasets(extract_das_and_call_yeo_johnson_transform,\n",
    "    tas_stacked_y,\n",
    "    resids_after_hm,\n",
    "    pt_coefficients,\n",
    ")\n",
    "transformed_hm_resids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit cyclo-stationary AR(1) process\n",
    "\n",
    "The monthly residuals are now assumed to follow a cyclo-stationary AR(1) process, where e.g. the July residuals depend on the ones from June and the ones of June on May's with distinct parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_da_and_fit_AR(ds_m, time_dim):\n",
    "    monthly_dat = ds_m.transformed\n",
    "    return mesmer.stats.fit_auto_regression_monthly(monthly_dat, time_dim=time_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR1_fit = map_over_datasets(extract_da_and_fit_AR,\n",
    "    transformed_hm_resids, kwargs={\"time_dim\": \"time\"}\n",
    ")\n",
    "AR1_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR1_fit_scen_mean = _avg_ens_then_scen(AR1_fit)\n",
    "AR1_fit_scen_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find localized empirical covariance\n",
    "\n",
    "Finally, we determine the localized empirical spatial covariance for each month separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodist = mesmer.geospatial.geodist_exact(\n",
    "    tas_stacked_y.historical.lon, tas_stacked_y.historical.lat\n",
    ")\n",
    "\n",
    "phi_gc_localizer = mesmer.stats.gaspari_cohn_correlation_matrices(\n",
    "    geodist, localisation_radii=LOCALISATION_RADII\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR1_residuals = map_over_datasets(lambda ds: ds[\"residuals\"], AR1_fit)\n",
    "weights = mesmer.weighted.equal_scenario_weights_from_datatree(AR1_residuals)\n",
    "\n",
    "AR1_residuals_ds = mesmer.datatree.collapse_datatree_into_dataset(\n",
    "    AR1_residuals, dim=\"scenario\"\n",
    ")\n",
    "weights_ds = mesmer.datatree.collapse_datatree_into_dataset(weights, dim=\"scenario\")\n",
    "\n",
    "monthly_resids = AR1_residuals_ds.residuals.groupby(\"time.month\")\n",
    "monthly_weights = weights_ds.weights.groupby(\"time.month\")\n",
    "\n",
    "localized_ecov = []\n",
    "\n",
    "for mon in range(1, 13):\n",
    "    data = monthly_resids[mon]\n",
    "    data = data.stack(sample=(\"scenario\", \"member\", \"time\"), create_index=False)\n",
    "    data = data.dropna(dim=\"sample\")\n",
    "\n",
    "    mon_weights = monthly_weights[mon]\n",
    "    mon_weights = mon_weights.stack(\n",
    "        sample=(\"scenario\", \"member\", \"time\"), create_index=False\n",
    "    )\n",
    "    mon_weights = mon_weights.dropna(dim=\"sample\")\n",
    "\n",
    "    res = mesmer.stats.find_localized_empirical_covariance(\n",
    "        data,\n",
    "        mon_weights,\n",
    "        phi_gc_localizer,\n",
    "        dim=\"sample\",\n",
    "        k_folds=30,\n",
    "    )\n",
    "    localized_ecov.append(res)\n",
    "\n",
    "month = xr.DataArray(range(1, 13), dims=\"month\")\n",
    "localized_ecov = xr.concat(localized_ecov, dim=month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time coordinate\n",
    "We need to get the original time coordinate to be able to validate our results later on. If it is not needed to align the final emulations with the original data, this can be omitted, the time coordinates can later be generated for example with \n",
    "\n",
    "\n",
    "```python\n",
    "monthly_time = xr.cftime_range(\"1850-01-01\", \"2100-12-31\", freq=\"MS\", calendar=\"gregorian\")\n",
    "monthly_time = xr.DataArray(monthly_time, dims=\"time\", coords={\"time\": monthly_time})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and save time coordinate\n",
    "hist_time = tas_stacked_m.historical.time\n",
    "scen_time = tas_stacked_m.ssp585.time\n",
    "m_time = xr.concat([hist_time, scen_time], dim=\"time\")\n",
    "\n",
    "# TODO\n",
    "# save the parameters to a file\n",
    "# harmonic_model_fit\n",
    "# pt_coefficients\n",
    "# AR1_fit\n",
    "# localized_ecov\n",
    "# m_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make emulations\n",
    "\n",
    "To generate emulations the workflow of the calibration is reversed, using the estimated parameters from above. Here, we use the same local annual mean temperatures to force the emulations, but temperatures from other models, scenarios, ensemble members or emulated annual local temperatures can be used as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Re-import necessary libraries\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "NR_EMUS = 10\n",
    "BUFFER = 20\n",
    "# REF_PERIOD = slice(\"1850\", \"1900\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random number seed\n",
    "\n",
    "The `seed` determines the initial state for the random number generator. To avoid generating the same noise for different models and scenarios different seeds are required for each individual paring. For reproducibility the seed needs to be the same for any subsequent draw of the same emulator. To avoid human chosen standard seeds (e.g. `0`, `1234`) its recommended to also randomly generate the seeds and save them for later, using\n",
    "\n",
    "```python\n",
    "import secrets\n",
    "secrets.randbits(128)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random but constant\n",
    "SEED = 234361146192407661971285321853135632294"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data needed for emulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# load the parameters from a file\n",
    "# in this example notebook we directly use the calibration from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# load yearly temperature\n",
    "# in this example we are using the original yearly temperature for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess tas\n",
    "# ref = tas_y.sel(time=REF_PERIOD).mean(\"time\", keep_attrs=True)\n",
    "# tas_y = tas_y - ref\n",
    "# tas_stacked_y = mask_and_stack(tas_y, threshold_land=THRESHOLD_LAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the original grid for transforming back later\n",
    "grid_orig = ref_y.to_dataset()[[\"lat\", \"lon\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate emulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_predictor = xr.concat(\n",
    "    [\n",
    "        tas_stacked_y.historical.tas.isel(member=0),\n",
    "        tas_stacked_y.ssp585.tas.isel(member=0),\n",
    "    ],\n",
    "    dim=\"time\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate monthly data with harmonic model\n",
    "monthly_harmonic_emu = mesmer.stats.predict_harmonic_model(\n",
    "    yearly_predictor, harmonic_model_fit_scen_mean.coeffs, m_time\n",
    ")\n",
    "\n",
    "# generate variability around 0 with AR(1) model\n",
    "local_variability_transformed = mesmer.stats.draw_auto_regression_monthly(\n",
    "    AR1_fit_scen_mean,\n",
    "    localized_ecov.localized_covariance,\n",
    "    time=m_time,\n",
    "    n_realisations=NR_EMUS,\n",
    "    seed=SEED,\n",
    "    buffer=BUFFER,\n",
    ")\n",
    "\n",
    "# invert the power transformation\n",
    "local_variability_inverted = mesmer.stats.inverse_yeo_johnson_transform(\n",
    "    yearly_predictor,\n",
    "    local_variability_transformed,\n",
    "    pt_coefficients_scen_mean.lambda_coeffs,\n",
    ")\n",
    "\n",
    "# add the local variability to the monthly harmonic\n",
    "emulations = monthly_harmonic_emu + local_variability_inverted.inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstack to original grid\n",
    "emulations_unstacked = mesmer.grid.unstack_lat_lon_and_align(emulations, grid_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulations_unstacked.isel(realisation=0, time=3011).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and/or Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesmer_dt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

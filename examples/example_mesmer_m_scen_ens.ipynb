{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example MESMER-M workflow for multiple scenarios and ensemble members\n",
    "\n",
    "Training and emulation of monthly local temperature from yearly local temperature. We use an example data set on a coarse grid.\n",
    "\n",
    "Import libraries and check MESMER version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filefisher\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "import mesmer\n",
    "from mesmer.core._datatreecompat import map_over_datasets\n",
    "\n",
    "mesmer.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate emulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCALISATION_RADII = list(range(1250, 6251, 250)) + list(range(6500, 8501, 500))\n",
    "THRESHOLD_LAND = 1 / 3\n",
    "REF_PERIOD = slice(\"1850\", \"1900\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths of the example data\n",
    "\n",
    "model = \"IPSL-CM6A-LR\"\n",
    "scenarios = [\"ssp126\", \"ssp585\"]\n",
    "\n",
    "cmip6_data_path = mesmer.example_data.cmip6_ng_path(relative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data for training the emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_FILEFINDER = filefisher.FileFinder(\n",
    "    path_pattern=cmip6_data_path / \"{variable}/{time_res}/{resolution}\",\n",
    "    file_pattern=\"{variable}_{time_res}_{model}_{scenario}_{member}_{resolution}.nc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find annual data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_scens_y = CMIP_FILEFINDER.find_files(\n",
    "    variable=\"tas\", scenario=scenarios, model=model, resolution=\"g025\", time_res=\"ann\"\n",
    ")\n",
    "\n",
    "# only get the historical members that are also in the future scenarios, but only once\n",
    "unique_scen_members_y = fc_scens_y.df.member.unique()\n",
    "\n",
    "fc_hist_y = CMIP_FILEFINDER.find_files(\n",
    "    variable=\"tas\",\n",
    "    scenario=\"historical\",\n",
    "    model=model,\n",
    "    resolution=\"g025\",\n",
    "    time_res=\"ann\",\n",
    "    member=unique_scen_members_y,\n",
    ")\n",
    "\n",
    "fc_all_y = fc_hist_y.concat(fc_scens_y)\n",
    "fc_all_y.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find monthly data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_scens_m = CMIP_FILEFINDER.find_files(\n",
    "    variable=\"tas\", scenario=scenarios, model=model, resolution=\"g025\", time_res=\"mon\"\n",
    ")\n",
    "\n",
    "# only get the historical members that are also in the future scenarios, but only once\n",
    "unique_scen_members_m = fc_scens_y.df.member.unique()\n",
    "\n",
    "fc_hist_m = CMIP_FILEFINDER.find_files(\n",
    "    variable=\"tas\",\n",
    "    scenario=\"historical\",\n",
    "    model=model,\n",
    "    resolution=\"g025\",\n",
    "    time_res=\"mon\",\n",
    "    member=unique_scen_members_m,\n",
    ")\n",
    "\n",
    "fc_all_m = fc_hist_m.concat(fc_scens_m)\n",
    "fc_all_m.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load annual data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_y = xr.DataTree()\n",
    "\n",
    "scenarios_whist = [\"historical\"] + scenarios\n",
    "\n",
    "# load data for each scenario\n",
    "for scen in scenarios_whist:\n",
    "    files = fc_all_y.search(scenario=scen)\n",
    "\n",
    "    # load all members for a scenario\n",
    "    members = []\n",
    "    for fN, meta in files.items():\n",
    "        time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
    "        ds = xr.open_dataset(fN, decode_times=time_coder)\n",
    "        # drop unnecessary variables\n",
    "        ds = ds.drop_vars([\"height\", \"time_bnds\", \"file_qf\"], errors=\"ignore\")\n",
    "        # assign member-ID as coordinate\n",
    "        ds = ds.assign_coords({\"member\": meta[\"member\"]})\n",
    "        members.append(ds)\n",
    "\n",
    "    # create a Dataset that holds each member along the member dimension\n",
    "    scen_data = xr.concat(members, dim=\"member\")\n",
    "    # put the scenario dataset into the DataTree\n",
    "    tas_y[f\"{scen}\"] = xr.DataTree(scen_data)\n",
    "\n",
    "tas_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load monthly data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_m = xr.DataTree()\n",
    "\n",
    "scenarios_whist = [\"historical\"] + scenarios\n",
    "\n",
    "# load data for each scenario\n",
    "for scen in scenarios_whist:\n",
    "    files = fc_all_m.search(scenario=scen)\n",
    "\n",
    "    # load all members for a scenario\n",
    "    members = []\n",
    "    for fN, meta in files.items():\n",
    "        time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
    "        ds = xr.open_dataset(fN, decode_times=time_coder)\n",
    "        # drop unnecessary variables\n",
    "        ds = ds.drop_vars([\"height\", \"time_bnds\", \"file_qf\"], errors=\"ignore\")\n",
    "        # assign member-ID as coordinate\n",
    "        ds = ds.assign_coords({\"member\": meta[\"member\"]})\n",
    "        members.append(ds)\n",
    "\n",
    "    # create a Dataset that holds each member along the member dimension\n",
    "    scen_data = xr.concat(members, dim=\"member\")\n",
    "    # put the scenario dataset into the DataTree\n",
    "    tas_m[f\"{scen}\"] = xr.DataTree(scen_data)\n",
    "\n",
    "tas_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Calculate anomalies w.r.t the reference period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_y = mesmer.anomaly.calc_anomaly(tas_y, reference_period=REF_PERIOD)\n",
    "tas_m = mesmer.anomaly.calc_anomaly(tas_m, reference_period=REF_PERIOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use land grid points and exclude Antarctica. The 3D data with dimensions `('time', 'lat', 'lon')` is stacked to 2D data with dimensions `('time', 'gridcell')`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_and_stack(ds, threshold_land):\n",
    "    ds = mesmer.mask.mask_ocean_fraction(ds, threshold_land)\n",
    "    ds = mesmer.mask.mask_antarctica(ds)\n",
    "    ds = mesmer.grid.stack_lat_lon(ds)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_stacked_y = mask_and_stack(tas_y, threshold_land=THRESHOLD_LAND)\n",
    "tas_stacked_m = mask_and_stack(tas_m, threshold_land=THRESHOLD_LAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mesmer.core.datatree\n",
    "\n",
    "\n",
    "tas_stacked_y_pooled = mesmer.core.datatree._stack_datatree(tas_stacked_y)\n",
    "tas_stacked_m_pooled = mesmer.core.datatree._stack_datatree(tas_stacked_m)\n",
    "\n",
    "\n",
    "tas_stacked_y_pooled.set_index(sample=(\"time\", \"member\", \"scenario\")).reindex_like(\n",
    "    tas_stacked_m_pooled.set_index(sample=(\"time\", \"member\", \"scenario\"))\n",
    ")\n",
    "\n",
    "\n",
    "# tas_stacked_y_pooled.set_index(sample=(\"time\", \"member\", \"scenario\"))\n",
    "\n",
    "# tas_stacked_y_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_stacked_y_pooled.expand_dims({\"new\": 12}).stack(\n",
    "    __sample__=(\"sample\", \"new\"), create_index=False\n",
    ").rename_dims(__sample__=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"sample\" in tas_stacked_y_pooled.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tas_stacked_m_pooled.time[0].item()\n",
    "\n",
    "d.replace(day=1, hour=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_stacked_y_pooled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the harmonic model\n",
    "\n",
    "Fit the seasonal cycle with a harmonic model which can vary with local annual mean temperature\n",
    "(fourier regression). Removes annual mean and, determines the optimal order and the coefficients\n",
    "of the harmonic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_da_and_call_func(func, *names):\n",
    "    # TODO: find a better solution for this\n",
    "\n",
    "    def inner(*args, **kwargs):\n",
    "\n",
    "        assert len(names) == len(args)\n",
    "\n",
    "        args = (\n",
    "            arg[name] if name is not None else arg for name, arg in zip(names, args)\n",
    "        )\n",
    "\n",
    "        out = func(*args, **kwargs)\n",
    "        return out\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mesmer.core._datatreecompat\n",
    "\n",
    "tas_stacked_y_from_m = mesmer.core._datatreecompat.map_over_datasets(\n",
    "    lambda x: x.resample(time=\"YE\").mean(), tas_stacked_m\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_model_fit = map_over_datasets(\n",
    "    extract_da_and_call_func(mesmer.stats.fit_harmonic_model, \"tas\", \"tas\"),\n",
    "    tas_stacked_y,\n",
    "    tas_stacked_m,\n",
    ")\n",
    "harmonic_model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_model_fit_from_m = map_over_datasets(\n",
    "    extract_da_and_call_func(mesmer.stats.fit_harmonic_model, \"tas\", \"tas\"),\n",
    "    tas_stacked_y_from_m,\n",
    "    tas_stacked_m,\n",
    ")\n",
    "harmonic_model_fit_from_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _avg_for_dtype(ds, dim):\n",
    "    def avg_da(da, dim):\n",
    "        if da.dtype == int:\n",
    "            return da.quantile(q=0.5, dim=dim, method=\"nearest\", skipna=True)\n",
    "        else:\n",
    "            return da.mean(dim=dim, skipna=True)\n",
    "\n",
    "    return ds.map(avg_da, dim=dim)\n",
    "\n",
    "\n",
    "def _avg_ens_then_scen(dt, ens_dim=\"member\"):\n",
    "    ens_mean = map_over_datasets(_avg_for_dtype, dt, kwargs={\"dim\": ens_dim})\n",
    "    ds_ens_mean = mesmer.datatree.collapse_datatree_into_dataset(\n",
    "        ens_mean, dim=\"scenario\"\n",
    "    )\n",
    "    scen_mean = _avg_for_dtype(ds_ens_mean, dim=\"scenario\")\n",
    "    return scen_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over ensemble members and scenarios\n",
    "# do not average predictions, drop time dim (is only present on predicitions) to avoid nans\n",
    "harmonic_model_fit_wo_preds = harmonic_model_fit\n",
    "# .drop_vars((\"predictions\", \"time\"))\n",
    "harmonic_model_fit_scen_mean = _avg_ens_then_scen(harmonic_model_fit_wo_preds)\n",
    "harmonic_model_fit_scen_mean = harmonic_model_fit_scen_mean.drop_vars(\"quantile\")\n",
    "harmonic_model_fit_scen_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over ensemble members and scenarios\n",
    "# do not average predictions, drop time dim (is only present on predicitions) to avoid nans\n",
    "\n",
    "# .drop_vars((\"predictions\", \"time\"))\n",
    "harmonic_model_fit_scen_mean_from_m = _avg_ens_then_scen(harmonic_model_fit_from_m)\n",
    "harmonic_model_fit_scen_mean_from_m = harmonic_model_fit_scen_mean_from_m.drop_vars(\n",
    "    \"quantile\"\n",
    ")\n",
    "harmonic_model_fit_scen_mean_from_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING DIFFERENT WAYS TO ESTIMATE harmonic model - to clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_harmonic_model given mean of individual estimates\n",
    "preds_indiv_mean = map_over_datasets(\n",
    "    extract_da_and_call_func(\n",
    "        mesmer.stats.predict_harmonic_model, \"tas\", None, \"time\", None\n",
    "    ),\n",
    "    tas_stacked_y,\n",
    "    harmonic_model_fit_scen_mean.coeffs,\n",
    "    tas_stacked_m,\n",
    "    \"time\",\n",
    ")\n",
    "preds_indiv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_harmonic_model given mean of individual estimates\n",
    "preds_indiv_mean_from_m = map_over_datasets(\n",
    "    extract_da_and_call_func(\n",
    "        mesmer.stats.predict_harmonic_model, \"tas\", None, \"time\", None\n",
    "    ),\n",
    "    tas_stacked_y_from_m,\n",
    "    harmonic_model_fit_scen_mean_from_m.coeffs,\n",
    "    tas_stacked_m,\n",
    "    \"time\",\n",
    ")\n",
    "preds_indiv_mean_from_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pool data and estimate\n",
    "\n",
    "needs to be done manually - we cannot `upsample_yearly_data` _after_ stacking (time must be monotonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_stacked_stacked_m.time[0].dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_stacked_stacked_y_from_m.tas.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tas = tas_stacked_stacked_y_from_m.tas\n",
    "\n",
    "# tas.rename?\n",
    "\n",
    "time_dim: str = \"time\"\n",
    "sample_dim: str = \"sample\"\n",
    "\n",
    "monthly_time = tas_stacked_stacked_m.time\n",
    "\n",
    "\n",
    "(\n",
    "    tas_stacked_stacked_y_from_m.tas.expand_dims({\"__new__\": 12})\n",
    "    .stack(__sample__=(sample_dim, \"__new__\"), create_index=False)\n",
    "    .rename(__sample__=sample_dim)\n",
    "    .assign_coords({time_dim: monthly_time})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack\n",
    "\n",
    "\n",
    "tas_stacked_y_from_m\n",
    "tas_stacked_m\n",
    "\n",
    "tas_stacked_stacked_y_from_m = mesmer.core.datatree._stack_datatree(\n",
    "    tas_stacked_y_from_m\n",
    ")\n",
    "tas_stacked_stacked_m = mesmer.core.datatree._stack_datatree(tas_stacked_m)\n",
    "\n",
    "\n",
    "tas_stacked_stacked_m\n",
    "\n",
    "\n",
    "mesmer.stats.fit_harmonic_model(\n",
    "    tas_stacked_stacked_y_from_m.tas, tas_stacked_stacked_m.tas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_stacked_stacked_y_from_m.tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import mesmer.core.datatree\n",
    "import mesmer.core.utils\n",
    "from mesmer.stats._harmonic_model import _fit_fourier_order_np\n",
    "\n",
    "\n",
    "def fit_harmonic_model_datatree(\n",
    "    yearly_predictor: xr.DataArray,\n",
    "    monthly_target: xr.DataArray,\n",
    "    *,\n",
    "    max_order: int = 6,\n",
    "    time_dim: str = \"time\",\n",
    "    sample_dim: str = \"sample\",\n",
    ") -> xr.Dataset:\n",
    "\n",
    "    yearly_predictor = mesmer.core.utils.upsample_yearly_data(\n",
    "        yearly_predictor, monthly_target, time_dim=time_dim\n",
    "    )\n",
    "\n",
    "    # stack\n",
    "    yearly_predictor = mesmer.core.datatree._stack_datatree(\n",
    "        yearly_predictor, time_dim=time_dim, sample_dim=sample_dim\n",
    "    )\n",
    "    monthly_target = mesmer.core.datatree._stack_datatree(\n",
    "        monthly_target, time_dim=time_dim, sample_dim=sample_dim\n",
    "    )\n",
    "\n",
    "    # extract variable\n",
    "    yearly_predictor = yearly_predictor.tas\n",
    "    monthly_target = monthly_target.tas\n",
    "\n",
    "    # subtract annual mean to have seasonal anomalies around 0\n",
    "    seasonal_deviations = monthly_target - yearly_predictor\n",
    "\n",
    "    selected_order, coeffs, preds = xr.apply_ufunc(\n",
    "        _fit_fourier_order_np,\n",
    "        yearly_predictor,\n",
    "        seasonal_deviations,\n",
    "        input_core_dims=[[sample_dim], [sample_dim]],\n",
    "        output_core_dims=([], [\"coeff\"], [sample_dim]),\n",
    "        vectorize=True,\n",
    "        output_dtypes=[int, float, float],\n",
    "        kwargs={\"max_order\": max_order},\n",
    "    )\n",
    "\n",
    "    coeffs = coeffs.assign_coords({\"coeff\": np.arange(coeffs.sizes[\"coeff\"])})\n",
    "\n",
    "    resids = monthly_target - (yearly_predictor + preds)\n",
    "\n",
    "    data_vars = {\n",
    "        \"selected_order\": selected_order,\n",
    "        \"coeffs\": coeffs,\n",
    "        \"residuals\": resids.transpose(sample_dim, ...),\n",
    "    }\n",
    "\n",
    "    return xr.Dataset(data_vars)\n",
    "\n",
    "\n",
    "harmonic_model_fit_pooled = fit_harmonic_model_datatree(\n",
    "    tas_stacked_y,\n",
    "    tas_stacked_m,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_model_fit_pooled_y_from_m = fit_harmonic_model_datatree(\n",
    "    tas_stacked_y_from_m,\n",
    "    tas_stacked_m,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_pooled_from_m = (harmonic_model_fit_pooled_y_from_m.residuals**2).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_model_fit_pooled = fit_harmonic_model_datatree(\n",
    "    tas_stacked_y,\n",
    "    tas_stacked_m,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_model_fit_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_pooled = (harmonic_model_fit_pooled.residuals**2).sum().item()\n",
    "\n",
    "\n",
    "rss_indiv = 0\n",
    "for scen, ds in harmonic_model_fit.items():\n",
    "    rss_indiv += (ds.residuals**2).sum()\n",
    "rss_indiv = rss_indiv.item()\n",
    "\n",
    "\n",
    "rss_indiv_from_m = 0\n",
    "for scen, ds in harmonic_model_fit_from_m.items():\n",
    "    rss_indiv_from_m += (ds.residuals**2).sum()\n",
    "rss_indiv_from_m = rss_indiv_from_m.item()\n",
    "\n",
    "\n",
    "rss_ave = 0\n",
    "for scen, (p, tas) in xr.group_subtrees(preds_indiv_mean, tas_stacked_m):\n",
    "    if p.has_data:\n",
    "        rss_ave += ((p.pred - tas.tas) ** 2).sum()\n",
    "\n",
    "rss_ave = rss_ave.item()\n",
    "\n",
    "rss_ave_from_m = 0\n",
    "for scen, (p, tas) in xr.group_subtrees(preds_indiv_mean_from_m, tas_stacked_m):\n",
    "    if p.has_data:\n",
    "        rss_ave_from_m += ((p.pred - tas.tas) ** 2).sum()\n",
    "\n",
    "rss_ave_from_m = rss_ave_from_m.item()\n",
    "\n",
    "\n",
    "print(f\"{rss_indiv         = :0.0f}\")\n",
    "print(f\"{rss_indiv_from_m  = :0.0f}\")\n",
    "\n",
    "print(f\"{rss_ave           = :0.0f}\")\n",
    "print(f\"{rss_ave_from_m    = :0.0f}\")\n",
    "\n",
    "print(f\"{rss_pooled        = :0.0f}\")\n",
    "print(f\"{rss_pooled_from_m = :0.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"historical\": \"k\",\n",
    "    \"ssp126\": \"b\",\n",
    "    \"ssp585\": \"r\",\n",
    "}\n",
    "\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "for i, (p, ds) in enumerate(harmonic_model_fit.items()):\n",
    "    ds.coeffs.isel(coeff=0).plot(\n",
    "        hue=\"member\", color=colors[p], add_legend=False, lw=1, ax=ax\n",
    "    )\n",
    "    print(p)\n",
    "\n",
    "\n",
    "for scen, color in colors.items():\n",
    "    ax.plot(np.nan, np.nan, label=scen, color=color)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set_ylabel(r\"$\\cos$\")\n",
    "ax.set_title(r\"$\\cdot 1$\")\n",
    "ax.axhline(0, color=\"0.1\", lw=0.5)\n",
    "\n",
    "plt.savefig(\"coeffs_per_scen.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"k\", \"b\", \"r\"]\n",
    "\n",
    "\n",
    "f, axs = plt.subplots(2, 2, sharex=True, layout=\"constrained\")\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "# ax = axs[0, 0]\n",
    "\n",
    "\n",
    "for c in range(4):\n",
    "\n",
    "    ax = axs[c]\n",
    "\n",
    "    for i, (p, ds) in enumerate(harmonic_model_fit.items()):\n",
    "        ds.coeffs.isel(coeff=c).plot(\n",
    "            hue=\"member\", color=\"0.5\", add_legend=False, ax=ax, lw=1\n",
    "        )\n",
    "        print(p)\n",
    "\n",
    "    harmonic_model_fit_pooled.coeffs.isel(coeff=c).plot(ax=ax, label=\"pooled\")\n",
    "    harmonic_model_fit_scen_mean.coeffs.isel(coeff=c).plot(ax=ax, label=\"averaged\")\n",
    "\n",
    "    ax.axhline(0, lw=0.5, color=\"0.1\")\n",
    "\n",
    "    ax.set_title(\"\")\n",
    "\n",
    "\n",
    "axs[0].set_xlabel(\"\")\n",
    "axs[1].set_xlabel(\"\")\n",
    "\n",
    "axs[1].set_ylabel(\"\")\n",
    "axs[3].set_ylabel(\"\")\n",
    "\n",
    "f.suptitle(\"coeffs harmonic model\")\n",
    "\n",
    "axs[0].legend()\n",
    "\n",
    "\n",
    "axs[0].set_title(r\"$\\cdot \\mathrm{T}$\")\n",
    "axs[1].set_title(r\"$\\cdot 1$\")\n",
    "\n",
    "\n",
    "axs[0].set_ylabel(r\"$\\cos$\")\n",
    "axs[2].set_ylabel(r\"$\\sin$\")\n",
    "\n",
    "\n",
    "axs[0].set_title(\"(a)\", loc=\"left\")\n",
    "axs[1].set_title(\"(b)\", loc=\"left\")\n",
    "axs[2].set_title(\"(c)\", loc=\"left\")\n",
    "axs[3].set_title(\"(d)\", loc=\"left\")\n",
    "\n",
    "\n",
    "plt.savefig(\"coeffs.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the power transformer\n",
    "\n",
    "The residuals are not necessarily symmetric - make them more normal using a Yeo-Johnson\n",
    "transformation. The parameter $\\lambda$ is modelled with a logistic regression using\n",
    "local annual mean temperature as covariate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# harmonic_model_predictions = harmonic_model\n",
    "# resids_after_hm = map_over_datasets(\n",
    "#     lambda m_dat, hm_dat: m_dat - hm_dat.predictions, tas_stacked_m, harmonic_model_fit\n",
    "# )\n",
    "# resids_after_hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_stacked_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_coefficients = map_over_datasets(\n",
    "    extract_da_and_call_func(\n",
    "        mesmer.stats.fit_yeo_johnson_transform, \"tas\", \"residuals\"\n",
    "    ),\n",
    "    tas_stacked_y,\n",
    "    harmonic_model_fit,\n",
    ")\n",
    "pt_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_stacked_y\n",
    "\n",
    "tas_stacked_stacked_y = mesmer.core.datatree._stack_datatree(tas_stacked_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_coefficients_pooled = mesmer.stats.fit_yeo_johnson_transform(\n",
    "    tas_stacked_stacked_y.tas, harmonic_model_fit_pooled.residuals, time_dim=\"sample\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_coefficients_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_coefficients_scen_mean = _avg_ens_then_scen(pt_coefficients)\n",
    "pt_coefficients_scen_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 2\n",
    "coeff = 0\n",
    "\n",
    "for scen, ds in pt_coefficients.items():\n",
    "\n",
    "    for member in ds.member:\n",
    "        ds.lambda_coeffs.isel(month=month, coeff=coeff).sel(member=member).plot(\n",
    "            color=\"0.5\"\n",
    "        )\n",
    "\n",
    "\n",
    "pt_coefficients_pooled.lambda_coeffs.isel(month=month, coeff=coeff).plot()\n",
    "\n",
    "pt_coefficients_scen_mean.lambda_coeffs.isel(month=month, coeff=coeff).plot()\n",
    "\n",
    "\n",
    "plt.ylim(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_das_and_call_yeo_johnson_transform(ds_y, ds_m, lambda_coeffs_ds):\n",
    "    yearly_dat = ds_y.tas\n",
    "    monthly_dat = ds_m.tas\n",
    "    lambda_coeffs = lambda_coeffs_ds.lambda_coeffs\n",
    "    return mesmer.stats.yeo_johnson_transform(yearly_dat, monthly_dat, lambda_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_hm_resids = map_over_datasets(\n",
    "    extract_das_and_call_yeo_johnson_transform,\n",
    "    tas_stacked_y,\n",
    "    resids_after_hm,\n",
    "    pt_coefficients,\n",
    ")\n",
    "transformed_hm_resids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit cyclo-stationary AR(1) process\n",
    "\n",
    "The monthly residuals are now assumed to follow a cyclo-stationary AR(1) process, where e.g. the July residuals depend on the ones from June and the ones of June on May's with distinct parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_da_and_fit_AR(ds_m, time_dim):\n",
    "    monthly_dat = ds_m.transformed\n",
    "    return mesmer.stats.fit_auto_regression_monthly(monthly_dat, time_dim=time_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR1_fit = map_over_datasets(\n",
    "    extract_da_and_fit_AR, transformed_hm_resids, kwargs={\"time_dim\": \"time\"}\n",
    ")\n",
    "AR1_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR1_fit_scen_mean = _avg_ens_then_scen(AR1_fit)\n",
    "AR1_fit_scen_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find localized empirical covariance\n",
    "\n",
    "Finally, we determine the localized empirical spatial covariance for each month separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodist = mesmer.geospatial.geodist_exact(\n",
    "    tas_stacked_y.historical.lon, tas_stacked_y.historical.lat\n",
    ")\n",
    "\n",
    "phi_gc_localizer = mesmer.stats.gaspari_cohn_correlation_matrices(\n",
    "    geodist, localisation_radii=LOCALISATION_RADII\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR1_residuals = map_over_datasets(lambda ds: ds[\"residuals\"], AR1_fit)\n",
    "weights = mesmer.weighted.equal_scenario_weights_from_datatree(AR1_residuals)\n",
    "\n",
    "AR1_residuals_ds = mesmer.datatree.collapse_datatree_into_dataset(\n",
    "    AR1_residuals, dim=\"scenario\"\n",
    ")\n",
    "weights_ds = mesmer.datatree.collapse_datatree_into_dataset(weights, dim=\"scenario\")\n",
    "\n",
    "monthly_resids = AR1_residuals_ds.residuals.groupby(\"time.month\")\n",
    "monthly_weights = weights_ds.weights.groupby(\"time.month\")\n",
    "\n",
    "localized_ecov = []\n",
    "\n",
    "for mon in range(1, 13):\n",
    "    data = monthly_resids[mon]\n",
    "    data = data.stack(sample=(\"scenario\", \"member\", \"time\"), create_index=False)\n",
    "    data = data.dropna(dim=\"sample\")\n",
    "\n",
    "    mon_weights = monthly_weights[mon]\n",
    "    mon_weights = mon_weights.stack(\n",
    "        sample=(\"scenario\", \"member\", \"time\"), create_index=False\n",
    "    )\n",
    "    mon_weights = mon_weights.dropna(dim=\"sample\")\n",
    "\n",
    "    res = mesmer.stats.find_localized_empirical_covariance(\n",
    "        data,\n",
    "        mon_weights,\n",
    "        phi_gc_localizer,\n",
    "        dim=\"sample\",\n",
    "        k_folds=30,\n",
    "    )\n",
    "    localized_ecov.append(res)\n",
    "\n",
    "month = xr.DataArray(range(1, 13), dims=\"month\")\n",
    "localized_ecov = xr.concat(localized_ecov, dim=month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time coordinate\n",
    "We need to get the original time coordinate to be able to validate our results later on. If it is not needed to align the final emulations with the original data, this can be omitted, the time coordinates can later be generated for example with \n",
    "\n",
    "\n",
    "```python\n",
    "monthly_time = xr.cftime_range(\"1850-01-01\", \"2100-12-31\", freq=\"MS\", calendar=\"gregorian\")\n",
    "monthly_time = xr.DataArray(monthly_time, dims=\"time\", coords={\"time\": monthly_time})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and save time coordinate\n",
    "hist_time = tas_stacked_m.historical.time\n",
    "scen_time = tas_stacked_m.ssp585.time\n",
    "m_time = xr.concat([hist_time, scen_time], dim=\"time\")\n",
    "\n",
    "# TODO\n",
    "# save the parameters to a file\n",
    "# harmonic_model_fit\n",
    "# pt_coefficients\n",
    "# AR1_fit\n",
    "# localized_ecov\n",
    "# m_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make emulations\n",
    "\n",
    "To generate emulations the workflow of the calibration is reversed, using the estimated parameters from above. Here, we use the same local annual mean temperatures to force the emulations, but temperatures from other models, scenarios, ensemble members or emulated annual local temperatures can be used as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Re-import necessary libraries\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "NR_EMUS = 10\n",
    "BUFFER = 20\n",
    "# REF_PERIOD = slice(\"1850\", \"1900\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random number seed\n",
    "\n",
    "The `seed` determines the initial state for the random number generator. To avoid generating the same noise for different models and scenarios different seeds are required for each individual paring. For reproducibility the seed needs to be the same for any subsequent draw of the same emulator. To avoid human chosen standard seeds (e.g. `0`, `1234`) its recommended to also randomly generate the seeds and save them for later, using\n",
    "\n",
    "```python\n",
    "import secrets\n",
    "secrets.randbits(128)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random but constant\n",
    "SEED = 234361146192407661971285321853135632294"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data needed for emulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# load the parameters from a file\n",
    "# in this example notebook we directly use the calibration from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# load yearly temperature\n",
    "# in this example we are using the original yearly temperature for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess tas\n",
    "# ref = tas_y.sel(time=REF_PERIOD).mean(\"time\", keep_attrs=True)\n",
    "# tas_y = tas_y - ref\n",
    "# tas_stacked_y = mask_and_stack(tas_y, threshold_land=THRESHOLD_LAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the original grid for transforming back later\n",
    "grid_orig = ref_y.to_dataset()[[\"lat\", \"lon\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate emulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_predictor = xr.concat(\n",
    "    [\n",
    "        tas_stacked_y.historical.tas.isel(member=0),\n",
    "        tas_stacked_y.ssp585.tas.isel(member=0),\n",
    "    ],\n",
    "    dim=\"time\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate monthly data with harmonic model\n",
    "monthly_harmonic_emu = mesmer.stats.predict_harmonic_model(\n",
    "    yearly_predictor, harmonic_model_fit_scen_mean.coeffs, m_time\n",
    ")\n",
    "\n",
    "# generate variability around 0 with AR(1) model\n",
    "local_variability_transformed = mesmer.stats.draw_auto_regression_monthly(\n",
    "    AR1_fit_scen_mean,\n",
    "    localized_ecov.localized_covariance,\n",
    "    time=m_time,\n",
    "    n_realisations=NR_EMUS,\n",
    "    seed=SEED,\n",
    "    buffer=BUFFER,\n",
    ")\n",
    "\n",
    "# invert the power transformation\n",
    "local_variability_inverted = mesmer.stats.inverse_yeo_johnson_transform(\n",
    "    yearly_predictor,\n",
    "    local_variability_transformed,\n",
    "    pt_coefficients_scen_mean.lambda_coeffs,\n",
    ")\n",
    "\n",
    "# add the local variability to the monthly harmonic\n",
    "emulations = monthly_harmonic_emu + local_variability_inverted.inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstack to original grid\n",
    "emulations_unstacked = mesmer.grid.unstack_lat_lon_and_align(emulations, grid_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulations_unstacked.isel(realisation=0, time=3011).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and/or Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesmer_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
